{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicates Predictions \n",
    "## Based on TF-IDF Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing, svm, metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def pickle_store(obj, filename):\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(obj, file)\n",
    "\n",
    "def pickle_load(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(clf, clf_name, X, y, k=5):\n",
    "    starting_tm = time.time()\n",
    "    clf_precision = 0\n",
    "    clf_recall = 0\n",
    "    clf_f1 = 0\n",
    "    clf_accuracy = 0\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=k)\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        \n",
    "        clf_precision += metrics.precision_score(y_test, predictions, average='micro')\n",
    "        clf_recall += metrics.recall_score(y_test, predictions, average='micro')\n",
    "        clf_f1 += metrics.f1_score(y_test, predictions, average='micro')\n",
    "        clf_accuracy += metrics.accuracy_score(y_test, predictions)\n",
    "    \n",
    "     # compute the average of each value\n",
    "    precision_score = clf_precision/k\n",
    "    recall_score = clf_recall/k\n",
    "    f1_score = clf_f1/k\n",
    "    accuracy_score = clf_accuracy/k\n",
    "    \n",
    "    print(clf_name + \"\\nPrecision: \" + str(precision_score)\n",
    "          + \"\\nRecall: \" + str(recall_score)\n",
    "          + \"\\nF1-Measure: \" + str(f1_score) \n",
    "          + \"\\nAccuracy: \" + str(accuracy_score)\n",
    "          + \"\\nExecution time: \" + str(time.time() - starting_tm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "def grid_evaluattion(clf, msg, X, y, tuned_parameters, scores):\n",
    "    print(msg)\n",
    "    \n",
    "    # Split the dataset in two equal parts\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)    \n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\\n\" % score)\n",
    "    \n",
    "        clf = GridSearchCV(clf, tuned_parameters, scoring=score)\n",
    "        clf.fit(X_train, y_train)\n",
    "    \n",
    "        print(\"Best parameters set found on development set: \")\n",
    "        print(clf.best_params_)\n",
    "        print(\"\\nGrid scores on development set:\")\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))\n",
    "        print()\n",
    "    \n",
    "        print(\"Detailed classification report:\\n\")\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\\n\")\n",
    "        \n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print() \n",
    "\n",
    "# test all the classifiers\n",
    "def hyper_parameter_tuning(train_set, labels):\n",
    "    starting_tm = time.time()\n",
    "    rf = RandomForestClassifier(n_jobs=4)\n",
    "    msg = \"Using Random Forest Classifier\"\n",
    "    tuned_parameters = [{'n_estimators': [i*10 for i in range(10, 31)]}]\n",
    "    scores = ['accuracy']\n",
    "    grid_evaluattion(rf, msg, train_set, labels, tuned_parameters, scores)\n",
    "    \n",
    "    svm_clf = svm.SVC()\n",
    "    msg = \"Using SMV Classifier\"\n",
    "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1, 1e-1, 1e-2,], 'C': [10, 100, 1000]}]\n",
    "    scores = ['accuracy']\n",
    "    grid_evaluattion(svm_clf, msg, train_set, labels, tuned_parameters, scores)\n",
    "    \n",
    "    sgd_clf = SGDClassifier(n_jobs=12)\n",
    "    msg =\"Using Stohastic Gradient Descent\"\n",
    "    tuned_parameters = [{'loss':['hinge', 'modified_huber', 'log', 'squared_hinge'], 'max_iter':[3000]}]\n",
    "    scores = ['accuracy']\n",
    "    grid_evaluattion(sgd_clf, msg, train_set, labels, tuned_parameters, scores)\n",
    "    print(\"Execution time: \" + str(time.time() - starting_tm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "283004\n"
    }
   ],
   "source": [
    "data = data.fillna('')\n",
    "y = data[\"IsDuplicate\"]\n",
    "print(len(data[\"IsDuplicate\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfv = TfidfVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(283004, 73264)\n"
    }
   ],
   "source": [
    "q1q2 = data[\"Question1\"].fillna(\"\") \n",
    "q1q2 += \" \" + data[\"Question2\"].fillna(\"\")\n",
    "train = tfv.fit_transform(q1q2)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(283004, 180)\n"
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=180)\n",
    "train = svd.fit_transform(train)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Paramaters Look up\n",
    "\n",
    "- ## Stohastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Using Stohastic Gradient Descent\n# Tuning hyper-parameters for accuracy\n\nBest parameters set found on development set: \n{'loss': 'modified_huber', 'max_iter': 6000}\n\nGrid scores on development set:\n0.696 (+/-0.003) for {'loss': 'hinge', 'max_iter': 6000}\n0.705 (+/-0.003) for {'loss': 'modified_huber', 'max_iter': 6000}\n0.701 (+/-0.003) for {'loss': 'log', 'max_iter': 6000}\n0.605 (+/-0.030) for {'loss': 'squared_hinge', 'max_iter': 6000}\n\nDetailed classification report:\n\nThe model is trained on the full development set.\nThe scores are computed on the full evaluation set.\n\n              precision    recall  f1-score   support\n\n           0       0.71      0.89      0.79     88789\n           1       0.68      0.39      0.50     52713\n\n    accuracy                           0.70    141502\n   macro avg       0.70      0.64      0.64    141502\nweighted avg       0.70      0.70      0.68    141502\n\n\nExecution time: 3417.5345871448517\n"
    }
   ],
   "source": [
    "sgd_clf = SGDClassifier(n_jobs=12)\n",
    "msg =\"Using Stohastic Gradient Descent\"\n",
    "tuned_parameters = [{'loss':['hinge', 'modified_huber', 'log', 'squared_hinge'], 'max_iter':[6000]}]\n",
    "scores = ['accuracy']\n",
    "grid_evaluattion(sgd_clf, msg, train, y, tuned_parameters, scores)\n",
    "print(\"Execution time: \" + str(time.time() - starting_tm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_tm = time.time()\n",
    "rf = RandomForestClassifier(n_jobs=4)\n",
    "msg = \"Using Random Forest Classifier\"\n",
    "tuned_parameters = [{'n_estimators': [i*10 for i in range(30, 51)]}]\n",
    "scores = ['accuracy']\n",
    "grid_evaluattion(rf, msg, train, y, tuned_parameters, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Classifiers Performance using 283004 documents.\n\nRandom Forest Classifier\nPrecision: 0.7814871869849752\nRecall: 0.7814871869849752\nF1-Measure: 0.7814871869849752\nAccuracy: 0.7814871869849752\nExecution time: 5115.616062879562\n\n\n\nXGBoost\nPrecision: 0.7040960672637082\nRecall: 0.7040960672637082\nF1-Measure: 0.7040960672637082\nAccuracy: 0.7040960672637082\nExecution time: 811.0072736740112\n\n\n\nStohastic Gradient Descent\nPrecision: 0.7042939363222616\nRecall: 0.7042939363222616\nF1-Measure: 0.7042939363222616\nAccuracy: 0.7042939363222616\nExecution time: 11.409584283828735\n\n\n\n"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "print(\"Classifiers Performance using \" + str(train.shape[0]) + \" documents.\\n\")\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=460, n_jobs=4)\n",
    "# svm_clf =svm.SVC(gamma=0.1, C=10, kernel='rbf')\n",
    "sgd_clf = SGDClassifier(loss='modified_huber', max_iter=6000, n_jobs=4)\n",
    "xgb_clf = xgb.XGBClassifier(random_state=1,learning_rate=0.01)\n",
    "\n",
    "clfs = [(rf, \"Random Forest Classifier\"), (xgb_clf, \"XGBoost\"), (sgd_clf, \"Stohastic Gradient Descent\")]\n",
    "for clf, clf_name in clfs:\n",
    "    evaluation(clf, clf_name, train, y)\n",
    "    print(\"\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"data/test_without_labels.csv\")\n",
    "tfv = TfidfVectorizer(stop_words='english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(121287, 50444)\n"
    }
   ],
   "source": [
    "testq1q2 = test[\"Question1\"].fillna(\"\") \n",
    "testq1q2 += \" \" + test[\"Question2\"].fillna(\"\")\n",
    "vtest = tfv.fit_transform(testq1q2)\n",
    "print(vtest.shape)\n",
    "\n",
    "svd = TruncatedSVD(n_components=180)\n",
    "vtest = svd.fit_transform(vtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediciting with:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=460, n_jobs=4)\n",
    "rf.fit(train, y)\n",
    "predictions = rf.predict(vtest)\n",
    "\n",
    "# predictions_df = pd.DataFrame(data={'Id': list(test['Id']), 'Predicted':predictions})\n",
    "# predictions_df.to_csv(\"data/predictionsRFfull460_TF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf.predict(vtest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame(data={'Id': list(test['Id']), 'Predicted':predictions})\n",
    "predictions_df.to_csv(\"data/predictionsRFfull460_2_TF.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('anaconda3': virtualenv)",
   "language": "python",
   "name": "python37364bitanaconda3virtualenvb6e9a79795194820afdac05398fbbbc3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}